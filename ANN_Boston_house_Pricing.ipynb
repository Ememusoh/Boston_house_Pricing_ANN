{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1629424392720045"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X,Y), (x_test, y_test) = tf.keras.datasets.boston_housing.load_data()\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X,Y, test_size= 0.2)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc= MinMaxScaler()\n",
    "\n",
    "sc.fit(x_train)\n",
    "x_train = sc.transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "x_val = sc.transform(x_val)\n",
    "\n",
    "## this is the check if the values are too big to be used. if they are you normalize it\n",
    "\n",
    "x_train.min()\n",
    "x_train.max()\n",
    "x_test.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape\n",
    "\n",
    "## construct the \n",
    "## for regression, we do not use to activation = \"softmax\"\n",
    "## for regression, we do not use Conv2D because it is not an image\n",
    "## when the loss was much, i used Dropout\n",
    "\n",
    "input_to_model = tf.keras.layers.Input(shape = (13,), name = \"Input_to_model\")\n",
    "x = tf.keras.layers.Dense(256, activation = \"relu\")(input_to_model)\n",
    "x = tf.keras.layers.Dropout(0.1)(x)\n",
    "x = tf.keras.layers.Dense(256, activation= \"relu\")(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "output = tf.keras.layers.Dense(1, name = \"output_layer\")(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_to_model (InputLayer)  [(None, 13)]             0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 256)               3584      \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69,633\n",
      "Trainable params: 69,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "output.shape\n",
    "\n",
    "## train model\n",
    "model = tf.keras.Model(inputs = input_to_model, outputs = output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "## after training, we have to account for optimizer(Adam), loss(mean_square error(the lower the better))   \n",
    "## r2 square error is used after training the data\n",
    "## we try meas sqaure error, mean absolute error(for outlier)\n",
    "## i first tried \"mse\" then \"mae\"\n",
    "\n",
    "model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=1e-3), loss = \"mae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "11/11 [==============================] - 1s 27ms/step - loss: 21.8803 - val_loss: 19.0848\n",
      "Epoch 2/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 18.7718 - val_loss: 14.2015\n",
      "Epoch 3/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 12.8490 - val_loss: 7.4758\n",
      "Epoch 4/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 9.4374 - val_loss: 6.5250\n",
      "Epoch 5/1000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 8.1833 - val_loss: 5.2587\n",
      "Epoch 6/1000\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 6.8554 - val_loss: 4.5037\n",
      "Epoch 7/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 5.8409 - val_loss: 4.3055\n",
      "Epoch 8/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 5.2793 - val_loss: 4.4560\n",
      "Epoch 9/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 5.0230 - val_loss: 4.3527\n",
      "Epoch 10/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 4.9245 - val_loss: 4.1713\n",
      "Epoch 11/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 4.7481 - val_loss: 4.1068\n",
      "Epoch 12/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 4.5367 - val_loss: 3.8661\n",
      "Epoch 13/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 4.2984 - val_loss: 3.8512\n",
      "Epoch 14/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 4.3118 - val_loss: 3.5207\n",
      "Epoch 15/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 4.2993 - val_loss: 3.2950\n",
      "Epoch 16/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 4.2520 - val_loss: 3.3754\n",
      "Epoch 17/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 4.2089 - val_loss: 3.1394\n",
      "Epoch 18/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 3.9845 - val_loss: 3.0969\n",
      "Epoch 19/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 3.8668 - val_loss: 2.9944\n",
      "Epoch 20/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 3.7164 - val_loss: 2.8680\n",
      "Epoch 21/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 3.6537 - val_loss: 2.7325\n",
      "Epoch 22/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3.6660 - val_loss: 2.5721\n",
      "Epoch 23/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 3.6137 - val_loss: 2.7614\n",
      "Epoch 24/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 3.5631 - val_loss: 2.5849\n",
      "Epoch 25/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 3.5661 - val_loss: 2.4748\n",
      "Epoch 26/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 3.4325 - val_loss: 2.3429\n",
      "Epoch 27/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 3.2728 - val_loss: 2.6635\n",
      "Epoch 28/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 3.5327 - val_loss: 2.7678\n",
      "Epoch 29/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 3.2859 - val_loss: 2.4323\n",
      "Epoch 30/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 3.3154 - val_loss: 2.3661\n",
      "Epoch 31/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 3.2465 - val_loss: 2.2331\n",
      "Epoch 32/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 3.1476 - val_loss: 2.2619\n",
      "Epoch 33/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 3.1153 - val_loss: 2.3268\n",
      "Epoch 34/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 3.0824 - val_loss: 2.2002\n",
      "Epoch 35/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.8934 - val_loss: 2.2318\n",
      "Epoch 36/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 3.1631 - val_loss: 2.4099\n",
      "Epoch 37/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 3.0915 - val_loss: 2.2349\n",
      "Epoch 38/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.9085 - val_loss: 2.1555\n",
      "Epoch 39/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.9757 - val_loss: 2.3389\n",
      "Epoch 40/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.9865 - val_loss: 2.4112\n",
      "Epoch 41/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 3.0292 - val_loss: 2.2335\n",
      "Epoch 42/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.9427 - val_loss: 2.2019\n",
      "Epoch 43/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 3.0367 - val_loss: 2.4946\n",
      "Epoch 44/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 3.1684 - val_loss: 2.3364\n",
      "Epoch 45/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 3.0118 - val_loss: 2.3200\n",
      "Epoch 46/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.9219 - val_loss: 2.1754\n",
      "Epoch 47/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.7049 - val_loss: 2.2284\n",
      "Epoch 48/1000\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2.8482 - val_loss: 2.2194\n",
      "Epoch 49/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.9165 - val_loss: 2.3017\n",
      "Epoch 50/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.9054 - val_loss: 2.4957\n",
      "Epoch 51/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.7527 - val_loss: 2.3313\n",
      "Epoch 52/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.8344 - val_loss: 2.3266\n",
      "Epoch 53/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.8439 - val_loss: 2.3143\n",
      "Epoch 54/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.7425 - val_loss: 2.3846\n",
      "Epoch 55/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.7704 - val_loss: 2.2578\n",
      "Epoch 56/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.7540 - val_loss: 2.3421\n",
      "Epoch 57/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.7809 - val_loss: 2.3215\n",
      "Epoch 58/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.6104 - val_loss: 2.3381\n",
      "Epoch 59/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.6279 - val_loss: 2.3660\n",
      "Epoch 60/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.6274 - val_loss: 2.2610\n",
      "Epoch 61/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.6176 - val_loss: 2.1875\n",
      "Epoch 62/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.8114 - val_loss: 2.4059\n",
      "Epoch 63/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.6684 - val_loss: 2.2753\n",
      "Epoch 64/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.6294 - val_loss: 2.2568\n",
      "Epoch 65/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.6394 - val_loss: 2.4311\n",
      "Epoch 66/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.8056 - val_loss: 2.2790\n",
      "Epoch 67/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 2.7214 - val_loss: 2.2693\n",
      "Epoch 68/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.5782 - val_loss: 2.2324\n",
      "Epoch 69/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.7606 - val_loss: 2.2124\n",
      "Epoch 70/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.6061 - val_loss: 2.4240\n",
      "Epoch 71/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.6504 - val_loss: 2.5975\n",
      "Epoch 72/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.8906 - val_loss: 2.3182\n",
      "Epoch 73/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.6430 - val_loss: 2.2573\n",
      "Epoch 74/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.4583 - val_loss: 2.3479\n",
      "Epoch 75/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.6268 - val_loss: 2.3639\n",
      "Epoch 76/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.5330 - val_loss: 2.2874\n",
      "Epoch 77/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.7783 - val_loss: 2.7607\n",
      "Epoch 78/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.6550 - val_loss: 2.4399\n",
      "Epoch 79/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.6046 - val_loss: 2.3543\n",
      "Epoch 80/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.4884 - val_loss: 2.5379\n",
      "Epoch 81/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.5748 - val_loss: 2.4050\n",
      "Epoch 82/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.5755 - val_loss: 2.3266\n",
      "Epoch 83/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.3745 - val_loss: 2.3437\n",
      "Epoch 84/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.3987 - val_loss: 2.4258\n",
      "Epoch 85/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.4389 - val_loss: 2.5424\n",
      "Epoch 86/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.6174 - val_loss: 2.4403\n",
      "Epoch 87/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.3653 - val_loss: 2.4521\n",
      "Epoch 88/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.5595 - val_loss: 2.5401\n",
      "Epoch 89/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.6423 - val_loss: 2.3941\n",
      "Epoch 90/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.3575 - val_loss: 2.4042\n",
      "Epoch 91/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.4100 - val_loss: 2.5287\n",
      "Epoch 92/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.4230 - val_loss: 2.3704\n",
      "Epoch 93/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.4999 - val_loss: 2.3797\n",
      "Epoch 94/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.2503 - val_loss: 2.3457\n",
      "Epoch 95/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.3224 - val_loss: 2.3701\n",
      "Epoch 96/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.4310 - val_loss: 2.6375\n",
      "Epoch 97/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.4328 - val_loss: 2.3177\n",
      "Epoch 98/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.4275 - val_loss: 2.2461\n",
      "Epoch 99/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.3318 - val_loss: 2.3413\n",
      "Epoch 100/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.3128 - val_loss: 2.3436\n",
      "Epoch 101/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.4381 - val_loss: 2.3687\n",
      "Epoch 102/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.2965 - val_loss: 2.4010\n",
      "Epoch 103/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.2201 - val_loss: 2.4741\n",
      "Epoch 104/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.3315 - val_loss: 2.3471\n",
      "Epoch 105/1000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.3388 - val_loss: 2.4253\n",
      "Epoch 106/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.3693 - val_loss: 2.3863\n",
      "Epoch 107/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.2792 - val_loss: 2.5204\n",
      "Epoch 108/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.2729 - val_loss: 2.3011\n",
      "Epoch 109/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.4368 - val_loss: 2.5066\n",
      "Epoch 110/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.4743 - val_loss: 2.4102\n",
      "Epoch 111/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.2946 - val_loss: 2.2327\n",
      "Epoch 112/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.2880 - val_loss: 2.3763\n",
      "Epoch 113/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.2742 - val_loss: 2.3561\n",
      "Epoch 114/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.3904 - val_loss: 2.2656\n",
      "Epoch 115/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.3832 - val_loss: 2.3386\n",
      "Epoch 116/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.4813 - val_loss: 2.5545\n",
      "Epoch 117/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.3063 - val_loss: 2.2771\n",
      "Epoch 118/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.2339 - val_loss: 2.3093\n",
      "Epoch 119/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.2263 - val_loss: 2.3318\n",
      "Epoch 120/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.2302 - val_loss: 2.2664\n",
      "Epoch 121/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.1712 - val_loss: 2.3344\n",
      "Epoch 122/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.3145 - val_loss: 2.2973\n",
      "Epoch 123/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.2568 - val_loss: 2.4709\n",
      "Epoch 124/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.4789 - val_loss: 2.4718\n",
      "Epoch 125/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.3169 - val_loss: 2.2980\n",
      "Epoch 126/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.2515 - val_loss: 2.4633\n",
      "Epoch 127/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.3509 - val_loss: 2.2890\n",
      "Epoch 128/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.1922 - val_loss: 2.2946\n",
      "Epoch 129/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.2720 - val_loss: 2.2911\n",
      "Epoch 130/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.3245 - val_loss: 2.2656\n",
      "Epoch 131/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.2101 - val_loss: 2.2872\n",
      "Epoch 132/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.3649 - val_loss: 2.2662\n",
      "Epoch 133/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.1329 - val_loss: 2.3421\n",
      "Epoch 134/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.2253 - val_loss: 2.3372\n",
      "Epoch 135/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.2075 - val_loss: 2.3286\n",
      "Epoch 136/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.1452 - val_loss: 2.4107\n",
      "Epoch 137/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.1913 - val_loss: 2.4076\n",
      "Epoch 138/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.1070 - val_loss: 2.3943\n",
      "Epoch 139/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.2228 - val_loss: 2.3344\n",
      "Epoch 140/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.2806 - val_loss: 2.3587\n",
      "Epoch 141/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.1313 - val_loss: 2.4001\n",
      "Epoch 142/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.1999 - val_loss: 2.4240\n",
      "Epoch 143/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.1571 - val_loss: 2.3070\n",
      "Epoch 144/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.2673 - val_loss: 2.3412\n",
      "Epoch 145/1000\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2.2153 - val_loss: 2.4391\n",
      "Epoch 146/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.2529 - val_loss: 2.3002\n",
      "Epoch 147/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.2272 - val_loss: 2.3319\n",
      "Epoch 148/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.2696 - val_loss: 2.6127\n",
      "Epoch 149/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.3099 - val_loss: 2.4039\n",
      "Epoch 150/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.3446 - val_loss: 2.2734\n",
      "Epoch 151/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.1230 - val_loss: 2.2892\n",
      "Epoch 152/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.1741 - val_loss: 2.2862\n",
      "Epoch 153/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.2906 - val_loss: 2.3060\n",
      "Epoch 154/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.1817 - val_loss: 2.3446\n",
      "Epoch 155/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.2310 - val_loss: 2.3694\n",
      "Epoch 156/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.2111 - val_loss: 2.3474\n",
      "Epoch 157/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.2210 - val_loss: 2.2498\n",
      "Epoch 158/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.2836 - val_loss: 2.3887\n",
      "Epoch 159/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.1009 - val_loss: 2.4367\n",
      "Epoch 160/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.3036 - val_loss: 2.3442\n",
      "Epoch 161/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.2403 - val_loss: 2.2816\n",
      "Epoch 162/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.1419 - val_loss: 2.2411\n",
      "Epoch 163/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.1286 - val_loss: 2.3288\n",
      "Epoch 164/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.2590 - val_loss: 2.3003\n",
      "Epoch 165/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.1477 - val_loss: 2.4077\n",
      "Epoch 166/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.1952 - val_loss: 2.3681\n",
      "Epoch 167/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.1527 - val_loss: 2.3134\n",
      "Epoch 168/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.1934 - val_loss: 2.5527\n",
      "Epoch 169/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.3245 - val_loss: 2.5666\n",
      "Epoch 170/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.2405 - val_loss: 2.2905\n",
      "Epoch 171/1000\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 2.1680 - val_loss: 2.3174\n",
      "Epoch 172/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.1694 - val_loss: 2.2859\n",
      "Epoch 173/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.2018 - val_loss: 2.4040\n",
      "Epoch 174/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.2014 - val_loss: 2.4667\n",
      "Epoch 175/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.1631 - val_loss: 2.4430\n",
      "Epoch 176/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.3036 - val_loss: 2.2499\n",
      "Epoch 177/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.1150 - val_loss: 2.2410\n",
      "Epoch 178/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.0243 - val_loss: 2.2582\n",
      "Epoch 179/1000\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 2.0943 - val_loss: 2.2700\n",
      "Epoch 180/1000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.1450 - val_loss: 2.2970\n",
      "Epoch 181/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.1908 - val_loss: 2.2583\n",
      "Epoch 182/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.0595 - val_loss: 2.2643\n",
      "Epoch 183/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.1834 - val_loss: 2.2269\n",
      "Epoch 184/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.1213 - val_loss: 2.2054\n",
      "Epoch 185/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.0911 - val_loss: 2.2354\n",
      "Epoch 186/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.1939 - val_loss: 2.2946\n",
      "Epoch 187/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.2596 - val_loss: 2.2447\n",
      "Epoch 188/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.1764 - val_loss: 2.3084\n",
      "Epoch 189/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.1498 - val_loss: 2.3211\n",
      "Epoch 190/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.1499 - val_loss: 2.2337\n",
      "Epoch 191/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.2341 - val_loss: 2.3989\n",
      "Epoch 192/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.3170 - val_loss: 2.4325\n",
      "Epoch 193/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.2285 - val_loss: 2.2681\n",
      "Epoch 194/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.2821 - val_loss: 2.2872\n",
      "Epoch 195/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.1534 - val_loss: 2.2982\n",
      "Epoch 196/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.1065 - val_loss: 2.1807\n",
      "Epoch 197/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.0848 - val_loss: 2.1831\n",
      "Epoch 198/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.1685 - val_loss: 2.2117\n",
      "Epoch 199/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.1403 - val_loss: 2.2411\n",
      "Epoch 200/1000\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 2.0773 - val_loss: 2.2698\n",
      "Epoch 201/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.0819 - val_loss: 2.2212\n",
      "Epoch 202/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.1974 - val_loss: 2.2085\n",
      "Epoch 203/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.1236 - val_loss: 2.3109\n",
      "Epoch 204/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.1505 - val_loss: 2.2199\n",
      "Epoch 205/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.0318 - val_loss: 2.2046\n",
      "Epoch 206/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.0276 - val_loss: 2.2197\n",
      "Epoch 207/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.0276 - val_loss: 2.2160\n",
      "Epoch 208/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.1144 - val_loss: 2.3903\n",
      "Epoch 209/1000\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 2.3542 - val_loss: 2.5065\n",
      "Epoch 210/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.2107 - val_loss: 2.3148\n",
      "Epoch 211/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.3048 - val_loss: 2.2868\n",
      "Epoch 212/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.0252 - val_loss: 2.2221\n",
      "Epoch 213/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.1624 - val_loss: 2.1987\n",
      "Epoch 214/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.1522 - val_loss: 2.2517\n",
      "Epoch 215/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.1819 - val_loss: 2.4635\n",
      "Epoch 216/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.2446 - val_loss: 2.2581\n",
      "Epoch 217/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.0011 - val_loss: 2.1622\n",
      "Epoch 218/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.1187 - val_loss: 2.1787\n",
      "Epoch 219/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.1263 - val_loss: 2.2254\n",
      "Epoch 220/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.1514 - val_loss: 2.2871\n",
      "Epoch 221/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.0245 - val_loss: 2.3256\n",
      "Epoch 222/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.2071 - val_loss: 2.2924\n",
      "Epoch 223/1000\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 2.1104 - val_loss: 2.3171\n",
      "Epoch 224/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.1153 - val_loss: 2.3154\n",
      "Epoch 225/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.2354 - val_loss: 2.3113\n",
      "Epoch 226/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.1613 - val_loss: 2.1959\n",
      "Epoch 227/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.0812 - val_loss: 2.2204\n",
      "Epoch 228/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.0826 - val_loss: 2.2873\n",
      "Epoch 229/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.1436 - val_loss: 2.3340\n",
      "Epoch 230/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.1485 - val_loss: 2.1713\n",
      "Epoch 231/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.2771 - val_loss: 2.2659\n",
      "Epoch 232/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.9072 - val_loss: 2.2969\n",
      "Epoch 233/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.1037 - val_loss: 2.1326\n",
      "Epoch 234/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.1225 - val_loss: 2.2110\n",
      "Epoch 235/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.1213 - val_loss: 2.1746\n",
      "Epoch 236/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.1125 - val_loss: 2.3055\n",
      "Epoch 237/1000\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 2.2498 - val_loss: 2.2410\n",
      "Epoch 238/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.0682 - val_loss: 2.2179\n",
      "Epoch 239/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.0826 - val_loss: 2.3897\n",
      "Epoch 240/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.2072 - val_loss: 2.2626\n",
      "Epoch 241/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.2036 - val_loss: 2.1558\n",
      "Epoch 242/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.0960 - val_loss: 2.1404\n",
      "Epoch 243/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.1156 - val_loss: 2.1330\n",
      "Epoch 244/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.0914 - val_loss: 2.2021\n",
      "Epoch 245/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.1742 - val_loss: 2.3705\n",
      "Epoch 246/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.1847 - val_loss: 2.1510\n",
      "Epoch 247/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.1928 - val_loss: 2.1388\n",
      "Epoch 248/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.1340 - val_loss: 2.2697\n",
      "Epoch 249/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.0300 - val_loss: 2.1356\n",
      "Epoch 250/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.9801 - val_loss: 2.1320\n",
      "Epoch 251/1000\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 2.0973 - val_loss: 2.1459\n",
      "Epoch 252/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.0250 - val_loss: 2.1468\n",
      "Epoch 253/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.1274 - val_loss: 2.1459\n",
      "Epoch 254/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.9958 - val_loss: 2.1027\n",
      "Epoch 255/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.9640 - val_loss: 2.1405\n",
      "Epoch 256/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.0682 - val_loss: 2.1968\n",
      "Epoch 257/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.1523 - val_loss: 2.3050\n",
      "Epoch 258/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.3403 - val_loss: 2.3691\n",
      "Epoch 259/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.0935 - val_loss: 2.2708\n",
      "Epoch 260/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.1501 - val_loss: 2.0872\n",
      "Epoch 261/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.0328 - val_loss: 2.1208\n",
      "Epoch 262/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.0549 - val_loss: 2.3052\n",
      "Epoch 263/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.0539 - val_loss: 2.1806\n",
      "Epoch 264/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.9875 - val_loss: 2.1598\n",
      "Epoch 265/1000\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.9463 - val_loss: 2.1532\n",
      "Epoch 266/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.0607 - val_loss: 2.1902\n",
      "Epoch 267/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.0042 - val_loss: 2.2331\n",
      "Epoch 268/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.9663 - val_loss: 2.1769\n",
      "Epoch 269/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.9714 - val_loss: 2.2363\n",
      "Epoch 270/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.1166 - val_loss: 2.3592\n",
      "Epoch 271/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.9862 - val_loss: 2.2470\n",
      "Epoch 272/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.0128 - val_loss: 2.1753\n",
      "Epoch 273/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.9923 - val_loss: 2.1036\n",
      "Epoch 274/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.0678 - val_loss: 2.1050\n",
      "Epoch 275/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.9927 - val_loss: 2.0939\n",
      "Epoch 276/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.0059 - val_loss: 2.1169\n",
      "Epoch 277/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.9901 - val_loss: 2.2030\n",
      "Epoch 278/1000\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 1.9806 - val_loss: 2.1790\n",
      "Epoch 279/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.1448 - val_loss: 2.2239\n",
      "Epoch 280/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.0925 - val_loss: 2.2965\n",
      "Epoch 281/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.1861 - val_loss: 2.4818\n",
      "Epoch 282/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.3167 - val_loss: 2.5615\n",
      "Epoch 283/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.1755 - val_loss: 2.3884\n",
      "Epoch 284/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.0737 - val_loss: 2.1752\n",
      "Epoch 285/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.0592 - val_loss: 2.1683\n",
      "Epoch 286/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.0442 - val_loss: 2.2080\n",
      "Epoch 287/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.8280 - val_loss: 2.1296\n",
      "Epoch 288/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.0304 - val_loss: 2.1376\n",
      "Epoch 289/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.9783 - val_loss: 2.1857\n",
      "Epoch 290/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.0406 - val_loss: 2.0978\n",
      "Epoch 291/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8992 - val_loss: 2.1270\n",
      "Epoch 292/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.9791 - val_loss: 2.1036\n",
      "Epoch 293/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.9482 - val_loss: 2.2720\n",
      "Epoch 294/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.9344 - val_loss: 2.1519\n",
      "Epoch 295/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.0351 - val_loss: 2.1674\n",
      "Epoch 296/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.9039 - val_loss: 2.2399\n",
      "Epoch 297/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.9235 - val_loss: 2.1852\n",
      "Epoch 298/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.0276 - val_loss: 2.3195\n",
      "Epoch 299/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.0118 - val_loss: 2.3016\n",
      "Epoch 300/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.2252 - val_loss: 2.1464\n",
      "Epoch 301/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.2151 - val_loss: 2.4113\n",
      "Epoch 302/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.1226 - val_loss: 2.1955\n",
      "Epoch 303/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.9544 - val_loss: 2.1440\n",
      "Epoch 304/1000\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 2.0004 - val_loss: 2.1575\n",
      "Epoch 305/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.9680 - val_loss: 2.1494\n",
      "Epoch 306/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.9617 - val_loss: 2.1650\n",
      "Epoch 307/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.9914 - val_loss: 2.1017\n",
      "Epoch 308/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.0355 - val_loss: 2.1801\n",
      "Epoch 309/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.0633 - val_loss: 2.0785\n",
      "Epoch 310/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.0023 - val_loss: 2.1565\n",
      "Epoch 311/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.0912 - val_loss: 2.1077\n",
      "Epoch 312/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.9348 - val_loss: 2.1178\n",
      "Epoch 313/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.9821 - val_loss: 2.2999\n",
      "Epoch 314/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.2062 - val_loss: 2.1762\n",
      "Epoch 315/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.9914 - val_loss: 2.1653\n",
      "Epoch 316/1000\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 2.0550 - val_loss: 2.1219\n",
      "Epoch 317/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.8536 - val_loss: 2.1209\n",
      "Epoch 318/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.0760 - val_loss: 2.1327\n",
      "Epoch 319/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.9037 - val_loss: 2.0792\n",
      "Epoch 320/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.0434 - val_loss: 2.1232\n",
      "Epoch 321/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.0186 - val_loss: 2.1028\n",
      "Epoch 322/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.9815 - val_loss: 2.1137\n",
      "Epoch 323/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.8905 - val_loss: 2.2090\n",
      "Epoch 324/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.0122 - val_loss: 2.1512\n",
      "Epoch 325/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.9859 - val_loss: 2.3295\n",
      "Epoch 326/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.0270 - val_loss: 2.2432\n",
      "Epoch 327/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.0055 - val_loss: 2.1711\n",
      "Epoch 328/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.8967 - val_loss: 2.0897\n",
      "Epoch 329/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.0855 - val_loss: 2.0716\n",
      "Epoch 330/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.9495 - val_loss: 2.1508\n",
      "Epoch 331/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.0497 - val_loss: 2.0858\n",
      "Epoch 332/1000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1.8957 - val_loss: 2.0653\n",
      "Epoch 333/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.9911 - val_loss: 2.0676\n",
      "Epoch 334/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.8965 - val_loss: 2.0971\n",
      "Epoch 335/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.1591 - val_loss: 2.2410\n",
      "Epoch 336/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.1416 - val_loss: 2.1347\n",
      "Epoch 337/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2.0211 - val_loss: 2.3639\n",
      "Epoch 338/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.0712 - val_loss: 2.2183\n",
      "Epoch 339/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.8889 - val_loss: 2.1509\n",
      "Epoch 340/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.8828 - val_loss: 2.1283\n",
      "Epoch 341/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8040 - val_loss: 2.1339\n",
      "Epoch 342/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8629 - val_loss: 2.0481\n",
      "Epoch 343/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.8783 - val_loss: 2.0691\n",
      "Epoch 344/1000\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 2.0359 - val_loss: 2.0636\n",
      "Epoch 345/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.0623 - val_loss: 2.4237\n",
      "Epoch 346/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.0910 - val_loss: 2.1624\n",
      "Epoch 347/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.0324 - val_loss: 2.1775\n",
      "Epoch 348/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.9852 - val_loss: 2.1462\n",
      "Epoch 349/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.0587 - val_loss: 2.1166\n",
      "Epoch 350/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.9204 - val_loss: 2.0856\n",
      "Epoch 351/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8982 - val_loss: 2.0932\n",
      "Epoch 352/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.0285 - val_loss: 2.0359\n",
      "Epoch 353/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.9489 - val_loss: 2.0482\n",
      "Epoch 354/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.9416 - val_loss: 2.0765\n",
      "Epoch 355/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8035 - val_loss: 2.0504\n",
      "Epoch 356/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8734 - val_loss: 2.0364\n",
      "Epoch 357/1000\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.9682 - val_loss: 2.0508\n",
      "Epoch 358/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.9081 - val_loss: 2.1184\n",
      "Epoch 359/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8913 - val_loss: 2.1095\n",
      "Epoch 360/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.0424 - val_loss: 2.2091\n",
      "Epoch 361/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.9933 - val_loss: 2.1993\n",
      "Epoch 362/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.9949 - val_loss: 2.1021\n",
      "Epoch 363/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.9507 - val_loss: 2.1230\n",
      "Epoch 364/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8804 - val_loss: 2.0878\n",
      "Epoch 365/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.0985 - val_loss: 2.2487\n",
      "Epoch 366/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.9710 - val_loss: 2.1068\n",
      "Epoch 367/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.9655 - val_loss: 2.1948\n",
      "Epoch 368/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.9771 - val_loss: 2.1041\n",
      "Epoch 369/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.9405 - val_loss: 2.0847\n",
      "Epoch 370/1000\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.8682 - val_loss: 2.1020\n",
      "Epoch 371/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.9029 - val_loss: 2.2619\n",
      "Epoch 372/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.9131 - val_loss: 2.1842\n",
      "Epoch 373/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.0425 - val_loss: 2.3317\n",
      "Epoch 374/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.0149 - val_loss: 2.1375\n",
      "Epoch 375/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.0965 - val_loss: 2.2651\n",
      "Epoch 376/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.9974 - val_loss: 2.2652\n",
      "Epoch 377/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.9024 - val_loss: 2.0776\n",
      "Epoch 378/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.8635 - val_loss: 2.1850\n",
      "Epoch 379/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.9170 - val_loss: 2.1761\n",
      "Epoch 380/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.8639 - val_loss: 2.2187\n",
      "Epoch 381/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.8150 - val_loss: 2.1368\n",
      "Epoch 382/1000\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 1.9462 - val_loss: 2.1273\n",
      "Epoch 383/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8725 - val_loss: 2.0916\n",
      "Epoch 384/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8328 - val_loss: 2.1260\n",
      "Epoch 385/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.9969 - val_loss: 2.2878\n",
      "Epoch 386/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.0260 - val_loss: 2.1225\n",
      "Epoch 387/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.1055 - val_loss: 2.2338\n",
      "Epoch 388/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.9189 - val_loss: 2.1207\n",
      "Epoch 389/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.9130 - val_loss: 2.0589\n",
      "Epoch 390/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.8359 - val_loss: 2.2227\n",
      "Epoch 391/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.2019 - val_loss: 2.1435\n",
      "Epoch 392/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.0535 - val_loss: 2.1785\n",
      "Epoch 393/1000\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 1.8435 - val_loss: 2.0630\n",
      "Epoch 394/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.9579 - val_loss: 2.1266\n",
      "Epoch 395/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8201 - val_loss: 2.1500\n",
      "Epoch 396/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.9411 - val_loss: 2.1040\n",
      "Epoch 397/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.9257 - val_loss: 2.1010\n",
      "Epoch 398/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.8931 - val_loss: 2.3329\n",
      "Epoch 399/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.9096 - val_loss: 2.1451\n",
      "Epoch 400/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.7844 - val_loss: 2.1045\n",
      "Epoch 401/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8827 - val_loss: 2.0688\n",
      "Epoch 402/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8907 - val_loss: 2.2237\n",
      "Epoch 403/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.0279 - val_loss: 2.3382\n",
      "Epoch 404/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.8902 - val_loss: 2.1169\n",
      "Epoch 405/1000\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 1.8631 - val_loss: 2.0835\n",
      "Epoch 406/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8459 - val_loss: 2.0887\n",
      "Epoch 407/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.9898 - val_loss: 2.4119\n",
      "Epoch 408/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.9650 - val_loss: 2.2042\n",
      "Epoch 409/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.0208 - val_loss: 2.1535\n",
      "Epoch 410/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7900 - val_loss: 2.1713\n",
      "Epoch 411/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.9288 - val_loss: 2.2390\n",
      "Epoch 412/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.8983 - val_loss: 2.2199\n",
      "Epoch 413/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8035 - val_loss: 2.2302\n",
      "Epoch 414/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8829 - val_loss: 2.1391\n",
      "Epoch 415/1000\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 1.9421 - val_loss: 2.1622\n",
      "Epoch 416/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.0392 - val_loss: 2.5095\n",
      "Epoch 417/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.0094 - val_loss: 2.1687\n",
      "Epoch 418/1000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1.7788 - val_loss: 2.1938\n",
      "Epoch 419/1000\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 1.7250 - val_loss: 2.1491\n",
      "Epoch 420/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7438 - val_loss: 2.0795\n",
      "Epoch 421/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.8971 - val_loss: 2.2029\n",
      "Epoch 422/1000\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 2.0340 - val_loss: 2.4610\n",
      "Epoch 423/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.9604 - val_loss: 2.1386\n",
      "Epoch 424/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.0231 - val_loss: 2.4409\n",
      "Epoch 425/1000\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 1.9438 - val_loss: 2.2076\n",
      "Epoch 426/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.9816 - val_loss: 2.2177\n",
      "Epoch 427/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8291 - val_loss: 2.0838\n",
      "Epoch 428/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.8679 - val_loss: 2.0963\n",
      "Epoch 429/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.0459 - val_loss: 2.2010\n",
      "Epoch 430/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8108 - val_loss: 2.1035\n",
      "Epoch 431/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.8548 - val_loss: 2.0944\n",
      "Epoch 432/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.8636 - val_loss: 2.0515\n",
      "Epoch 433/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.8578 - val_loss: 2.0888\n",
      "Epoch 434/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.8583 - val_loss: 2.0981\n",
      "Epoch 435/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7731 - val_loss: 2.2609\n",
      "Epoch 436/1000\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 1.9192 - val_loss: 2.1248\n",
      "Epoch 437/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.8046 - val_loss: 2.0662\n",
      "Epoch 438/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7189 - val_loss: 2.0640\n",
      "Epoch 439/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.8548 - val_loss: 2.2322\n",
      "Epoch 440/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.9169 - val_loss: 2.1397\n",
      "Epoch 441/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8356 - val_loss: 2.0819\n",
      "Epoch 442/1000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.0153 - val_loss: 2.1175\n",
      "Epoch 443/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.9685 - val_loss: 2.3892\n",
      "Epoch 444/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.9124 - val_loss: 2.2243\n",
      "Epoch 445/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.9391 - val_loss: 2.1701\n",
      "Epoch 446/1000\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 1.9640 - val_loss: 2.3936\n",
      "Epoch 447/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.0976 - val_loss: 2.3350\n",
      "Epoch 448/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.0272 - val_loss: 2.3298\n",
      "Epoch 449/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.8442 - val_loss: 2.3237\n",
      "Epoch 450/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.2055 - val_loss: 2.3753\n",
      "Epoch 451/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.8984 - val_loss: 2.1413\n",
      "Epoch 452/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7868 - val_loss: 2.1101\n",
      "Epoch 453/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8136 - val_loss: 2.1420\n",
      "Epoch 454/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.8459 - val_loss: 2.1480\n",
      "Epoch 455/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.9147 - val_loss: 2.2349\n",
      "Epoch 456/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.9012 - val_loss: 2.1953\n",
      "Epoch 457/1000\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 1.8616 - val_loss: 2.1290\n",
      "Epoch 458/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.9204 - val_loss: 2.1166\n",
      "Epoch 459/1000\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 1.7072 - val_loss: 2.1843\n",
      "Epoch 460/1000\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 1.9162 - val_loss: 2.2024\n",
      "Epoch 461/1000\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 1.8596 - val_loss: 2.2454\n",
      "Epoch 462/1000\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 1.8689 - val_loss: 2.2438\n",
      "Epoch 463/1000\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 2.0040 - val_loss: 2.1962\n",
      "Epoch 464/1000\n",
      "11/11 [==============================] - 0s 35ms/step - loss: 1.9648 - val_loss: 2.2287\n",
      "Epoch 465/1000\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 1.7571 - val_loss: 2.2212\n",
      "Epoch 466/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.8515 - val_loss: 2.1721\n",
      "Epoch 467/1000\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.8588 - val_loss: 2.1396\n",
      "Epoch 468/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.8743 - val_loss: 2.1377\n",
      "Epoch 469/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.8185 - val_loss: 2.2782\n",
      "Epoch 470/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.8295 - val_loss: 2.1522\n",
      "Epoch 471/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.6647 - val_loss: 2.1934\n",
      "Epoch 472/1000\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 1.8412 - val_loss: 2.1598\n",
      "Epoch 473/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7587 - val_loss: 2.2485\n",
      "Epoch 474/1000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1.8806 - val_loss: 2.2054\n",
      "Epoch 475/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.9040 - val_loss: 2.3237\n",
      "Epoch 476/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.8455 - val_loss: 2.2230\n",
      "Epoch 477/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.0021 - val_loss: 2.5257\n",
      "Epoch 478/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.1052 - val_loss: 2.2589\n",
      "Epoch 479/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.8227 - val_loss: 2.2117\n",
      "Epoch 480/1000\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.8592 - val_loss: 2.3405\n",
      "Epoch 481/1000\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 1.9349 - val_loss: 2.2640\n",
      "Epoch 482/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.9501 - val_loss: 2.2132\n",
      "Epoch 483/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.8243 - val_loss: 2.1733\n",
      "Epoch 484/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.8474 - val_loss: 2.1799\n",
      "Epoch 485/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7591 - val_loss: 2.1676\n",
      "Epoch 486/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.8241 - val_loss: 2.2383\n",
      "Epoch 487/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8954 - val_loss: 2.1360\n",
      "Epoch 488/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.7931 - val_loss: 2.1328\n",
      "Epoch 489/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.8534 - val_loss: 2.1763\n",
      "Epoch 490/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.8766 - val_loss: 2.2220\n",
      "Epoch 491/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8089 - val_loss: 2.1210\n",
      "Epoch 492/1000\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 1.8391 - val_loss: 2.1877\n",
      "Epoch 493/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8971 - val_loss: 2.2215\n",
      "Epoch 494/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.8078 - val_loss: 2.2381\n",
      "Epoch 495/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8757 - val_loss: 2.2437\n",
      "Epoch 496/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7982 - val_loss: 2.1967\n",
      "Epoch 497/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7775 - val_loss: 2.2232\n",
      "Epoch 498/1000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1.8156 - val_loss: 2.1233\n",
      "Epoch 499/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7850 - val_loss: 2.1575\n",
      "Epoch 500/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8878 - val_loss: 2.1833\n",
      "Epoch 501/1000\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 1.8405 - val_loss: 2.1176\n",
      "Epoch 502/1000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1.8033 - val_loss: 2.1777\n",
      "Epoch 503/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7667 - val_loss: 2.2432\n",
      "Epoch 504/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8545 - val_loss: 2.3218\n",
      "Epoch 505/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.8477 - val_loss: 2.1734\n",
      "Epoch 506/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.8163 - val_loss: 2.3408\n",
      "Epoch 507/1000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1.9451 - val_loss: 2.1475\n",
      "Epoch 508/1000\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.8384 - val_loss: 2.2320\n",
      "Epoch 509/1000\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 1.7120 - val_loss: 2.2736\n",
      "Epoch 510/1000\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 1.8113 - val_loss: 2.2081\n",
      "Epoch 511/1000\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 1.7750 - val_loss: 2.2700\n",
      "Epoch 512/1000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1.7436 - val_loss: 2.2279\n",
      "Epoch 513/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7789 - val_loss: 2.2972\n",
      "Epoch 514/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.9287 - val_loss: 2.2137\n",
      "Epoch 515/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.6588 - val_loss: 2.2277\n",
      "Epoch 516/1000\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 1.7516 - val_loss: 2.2331\n",
      "Epoch 517/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.9848 - val_loss: 2.2933\n",
      "Epoch 518/1000\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.7395 - val_loss: 2.1483\n",
      "Epoch 519/1000\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.7820 - val_loss: 2.1698\n",
      "Epoch 520/1000\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 1.8384 - val_loss: 2.1587\n",
      "Epoch 521/1000\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.7709 - val_loss: 2.4524\n",
      "Epoch 522/1000\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.8721 - val_loss: 2.3259\n",
      "Epoch 523/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.9086 - val_loss: 2.3746\n",
      "Epoch 524/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.7867 - val_loss: 2.3656\n",
      "Epoch 525/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7205 - val_loss: 2.2326\n",
      "Epoch 526/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7641 - val_loss: 2.2193\n",
      "Epoch 527/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.8099 - val_loss: 2.2439\n",
      "Epoch 528/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.8807 - val_loss: 2.2176\n",
      "Epoch 529/1000\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 1.7136 - val_loss: 2.2432\n",
      "Epoch 530/1000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1.8822 - val_loss: 2.2845\n",
      "Epoch 531/1000\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.7712 - val_loss: 2.1716\n",
      "Epoch 532/1000\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.8929 - val_loss: 2.1492\n",
      "Epoch 533/1000\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.8055 - val_loss: 2.1162\n",
      "Epoch 534/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7621 - val_loss: 2.1443\n",
      "Epoch 535/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.8072 - val_loss: 2.1824\n",
      "Epoch 536/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.7560 - val_loss: 2.2261\n",
      "Epoch 537/1000\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.7637 - val_loss: 2.3038\n",
      "Epoch 538/1000\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 1.7647 - val_loss: 2.2222\n",
      "Epoch 539/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.8042 - val_loss: 2.2031\n",
      "Epoch 540/1000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1.6839 - val_loss: 2.1675\n",
      "Epoch 541/1000\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 1.8382 - val_loss: 2.4666\n",
      "Epoch 542/1000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1.9863 - val_loss: 2.3306\n",
      "Epoch 543/1000\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.8032 - val_loss: 2.2779\n",
      "Epoch 544/1000\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.7691 - val_loss: 2.1596\n",
      "Epoch 545/1000\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 1.7764 - val_loss: 2.2572\n",
      "Epoch 546/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7875 - val_loss: 2.2330\n",
      "Epoch 547/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7699 - val_loss: 2.1732\n",
      "Epoch 548/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7773 - val_loss: 2.1545\n",
      "Epoch 549/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.8436 - val_loss: 2.1518\n",
      "Epoch 550/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.8081 - val_loss: 2.1439\n",
      "Epoch 551/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7831 - val_loss: 2.1879\n",
      "Epoch 552/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.8753 - val_loss: 2.2577\n",
      "Epoch 553/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6931 - val_loss: 2.2471\n",
      "Epoch 554/1000\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 1.7267 - val_loss: 2.2252\n",
      "Epoch 555/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7272 - val_loss: 2.1589\n",
      "Epoch 556/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.8547 - val_loss: 2.2285\n",
      "Epoch 557/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8431 - val_loss: 2.2904\n",
      "Epoch 558/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6991 - val_loss: 2.4281\n",
      "Epoch 559/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8988 - val_loss: 2.3659\n",
      "Epoch 560/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.8385 - val_loss: 2.1803\n",
      "Epoch 561/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7316 - val_loss: 2.1803\n",
      "Epoch 562/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6820 - val_loss: 2.1726\n",
      "Epoch 563/1000\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 1.6641 - val_loss: 2.2321\n",
      "Epoch 564/1000\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.7887 - val_loss: 2.2010\n",
      "Epoch 565/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7694 - val_loss: 2.1468\n",
      "Epoch 566/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7767 - val_loss: 2.1453\n",
      "Epoch 567/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7671 - val_loss: 2.1492\n",
      "Epoch 568/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.6746 - val_loss: 2.1677\n",
      "Epoch 569/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6695 - val_loss: 2.1628\n",
      "Epoch 570/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7557 - val_loss: 2.3048\n",
      "Epoch 571/1000\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 1.8423 - val_loss: 2.2661\n",
      "Epoch 572/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7812 - val_loss: 2.3465\n",
      "Epoch 573/1000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1.7032 - val_loss: 2.1863\n",
      "Epoch 574/1000\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.7755 - val_loss: 2.2326\n",
      "Epoch 575/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7763 - val_loss: 2.2288\n",
      "Epoch 576/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.8706 - val_loss: 2.3332\n",
      "Epoch 577/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.9304 - val_loss: 2.3455\n",
      "Epoch 578/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.9235 - val_loss: 2.3148\n",
      "Epoch 579/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7030 - val_loss: 2.2377\n",
      "Epoch 580/1000\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 1.8458 - val_loss: 2.2290\n",
      "Epoch 581/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7081 - val_loss: 2.2212\n",
      "Epoch 582/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7820 - val_loss: 2.2567\n",
      "Epoch 583/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7972 - val_loss: 2.1720\n",
      "Epoch 584/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7354 - val_loss: 2.2502\n",
      "Epoch 585/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7004 - val_loss: 2.2062\n",
      "Epoch 586/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.9589 - val_loss: 2.3442\n",
      "Epoch 587/1000\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.7349 - val_loss: 2.1891\n",
      "Epoch 588/1000\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 1.7862 - val_loss: 2.2151\n",
      "Epoch 589/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7021 - val_loss: 2.3239\n",
      "Epoch 590/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8570 - val_loss: 2.3064\n",
      "Epoch 591/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7670 - val_loss: 2.3591\n",
      "Epoch 592/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7149 - val_loss: 2.3457\n",
      "Epoch 593/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8067 - val_loss: 2.3286\n",
      "Epoch 594/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6829 - val_loss: 2.2472\n",
      "Epoch 595/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7104 - val_loss: 2.3058\n",
      "Epoch 596/1000\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.7179 - val_loss: 2.3261\n",
      "Epoch 597/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7141 - val_loss: 2.2271\n",
      "Epoch 598/1000\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.7054 - val_loss: 2.1787\n",
      "Epoch 599/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7103 - val_loss: 2.2388\n",
      "Epoch 600/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7404 - val_loss: 2.2568\n",
      "Epoch 601/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6867 - val_loss: 2.2772\n",
      "Epoch 602/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7151 - val_loss: 2.3141\n",
      "Epoch 603/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7582 - val_loss: 2.1506\n",
      "Epoch 604/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7892 - val_loss: 2.2576\n",
      "Epoch 605/1000\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.8176 - val_loss: 2.2707\n",
      "Epoch 606/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7407 - val_loss: 2.2887\n",
      "Epoch 607/1000\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.9545 - val_loss: 2.1420\n",
      "Epoch 608/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6502 - val_loss: 2.1516\n",
      "Epoch 609/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7952 - val_loss: 2.2457\n",
      "Epoch 610/1000\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.6890 - val_loss: 2.3156\n",
      "Epoch 611/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6878 - val_loss: 2.1995\n",
      "Epoch 612/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.8119 - val_loss: 2.1723\n",
      "Epoch 613/1000\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 1.7479 - val_loss: 2.2644\n",
      "Epoch 614/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7575 - val_loss: 2.3396\n",
      "Epoch 615/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.8067 - val_loss: 2.3163\n",
      "Epoch 616/1000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1.7684 - val_loss: 2.2090\n",
      "Epoch 617/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7398 - val_loss: 2.1875\n",
      "Epoch 618/1000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1.6644 - val_loss: 2.3253\n",
      "Epoch 619/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7717 - val_loss: 2.2828\n",
      "Epoch 620/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.8624 - val_loss: 2.1795\n",
      "Epoch 621/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8359 - val_loss: 2.1985\n",
      "Epoch 622/1000\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 1.6393 - val_loss: 2.3145\n",
      "Epoch 623/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7193 - val_loss: 2.2192\n",
      "Epoch 624/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7157 - val_loss: 2.1875\n",
      "Epoch 625/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6458 - val_loss: 2.1633\n",
      "Epoch 626/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.8610 - val_loss: 2.1437\n",
      "Epoch 627/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7102 - val_loss: 2.1840\n",
      "Epoch 628/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7505 - val_loss: 2.1746\n",
      "Epoch 629/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.8048 - val_loss: 2.3149\n",
      "Epoch 630/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.0313 - val_loss: 2.2204\n",
      "Epoch 631/1000\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 1.7396 - val_loss: 2.1878\n",
      "Epoch 632/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7724 - val_loss: 2.2190\n",
      "Epoch 633/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.7858 - val_loss: 2.2515\n",
      "Epoch 634/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.9568 - val_loss: 2.3418\n",
      "Epoch 635/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8299 - val_loss: 2.2929\n",
      "Epoch 636/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.7028 - val_loss: 2.2795\n",
      "Epoch 637/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7604 - val_loss: 2.2979\n",
      "Epoch 638/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6507 - val_loss: 2.3711\n",
      "Epoch 639/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7671 - val_loss: 2.2754\n",
      "Epoch 640/1000\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 1.7714 - val_loss: 2.3033\n",
      "Epoch 641/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7872 - val_loss: 2.2952\n",
      "Epoch 642/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7348 - val_loss: 2.2796\n",
      "Epoch 643/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7514 - val_loss: 2.2598\n",
      "Epoch 644/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7749 - val_loss: 2.3779\n",
      "Epoch 645/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7094 - val_loss: 2.2535\n",
      "Epoch 646/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7013 - val_loss: 2.2998\n",
      "Epoch 647/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6640 - val_loss: 2.2307\n",
      "Epoch 648/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.7254 - val_loss: 2.2762\n",
      "Epoch 649/1000\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 1.7179 - val_loss: 2.3069\n",
      "Epoch 650/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7483 - val_loss: 2.3063\n",
      "Epoch 651/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.6618 - val_loss: 2.2139\n",
      "Epoch 652/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7826 - val_loss: 2.2628\n",
      "Epoch 653/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.0582 - val_loss: 2.3452\n",
      "Epoch 654/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.6993 - val_loss: 2.2359\n",
      "Epoch 655/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7775 - val_loss: 2.2263\n",
      "Epoch 656/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.8203 - val_loss: 2.2134\n",
      "Epoch 657/1000\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 1.7865 - val_loss: 2.2321\n",
      "Epoch 658/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7713 - val_loss: 2.2736\n",
      "Epoch 659/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.7219 - val_loss: 2.2805\n",
      "Epoch 660/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6948 - val_loss: 2.3381\n",
      "Epoch 661/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.8044 - val_loss: 2.2426\n",
      "Epoch 662/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6224 - val_loss: 2.3117\n",
      "Epoch 663/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6838 - val_loss: 2.2814\n",
      "Epoch 664/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.6303 - val_loss: 2.3204\n",
      "Epoch 665/1000\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.7524 - val_loss: 2.2852\n",
      "Epoch 666/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7151 - val_loss: 2.2243\n",
      "Epoch 667/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.5886 - val_loss: 2.2497\n",
      "Epoch 668/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7543 - val_loss: 2.2236\n",
      "Epoch 669/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.6952 - val_loss: 2.1792\n",
      "Epoch 670/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.9242 - val_loss: 2.3654\n",
      "Epoch 671/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8717 - val_loss: 2.1313\n",
      "Epoch 672/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.7439 - val_loss: 2.3144\n",
      "Epoch 673/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.8866 - val_loss: 2.3339\n",
      "Epoch 674/1000\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 1.6855 - val_loss: 2.2080\n",
      "Epoch 675/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6936 - val_loss: 2.1691\n",
      "Epoch 676/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.7970 - val_loss: 2.1884\n",
      "Epoch 677/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8157 - val_loss: 2.3239\n",
      "Epoch 678/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6745 - val_loss: 2.3407\n",
      "Epoch 679/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7414 - val_loss: 2.3138\n",
      "Epoch 680/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.6489 - val_loss: 2.2969\n",
      "Epoch 681/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.5962 - val_loss: 2.3864\n",
      "Epoch 682/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6188 - val_loss: 2.2820\n",
      "Epoch 683/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.6188 - val_loss: 2.3098\n",
      "Epoch 684/1000\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 1.7054 - val_loss: 2.2939\n",
      "Epoch 685/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6391 - val_loss: 2.2954\n",
      "Epoch 686/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.6354 - val_loss: 2.3274\n",
      "Epoch 687/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.6786 - val_loss: 2.3670\n",
      "Epoch 688/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8366 - val_loss: 2.3627\n",
      "Epoch 689/1000\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.7162 - val_loss: 2.2609\n",
      "Epoch 690/1000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1.7691 - val_loss: 2.2098\n",
      "Epoch 691/1000\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 1.7730 - val_loss: 2.2888\n",
      "Epoch 692/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8156 - val_loss: 2.2059\n",
      "Epoch 693/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7591 - val_loss: 2.1547\n",
      "Epoch 694/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7447 - val_loss: 2.2395\n",
      "Epoch 695/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7015 - val_loss: 2.2485\n",
      "Epoch 696/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6312 - val_loss: 2.2600\n",
      "Epoch 697/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.7211 - val_loss: 2.3185\n",
      "Epoch 698/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.7495 - val_loss: 2.2246\n",
      "Epoch 699/1000\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 1.6124 - val_loss: 2.2142\n",
      "Epoch 700/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7110 - val_loss: 2.2973\n",
      "Epoch 701/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.6297 - val_loss: 2.2401\n",
      "Epoch 702/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.6487 - val_loss: 2.2523\n",
      "Epoch 703/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.6726 - val_loss: 2.4505\n",
      "Epoch 704/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8760 - val_loss: 2.2597\n",
      "Epoch 705/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.8225 - val_loss: 2.3202\n",
      "Epoch 706/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.0164 - val_loss: 2.8956\n",
      "Epoch 707/1000\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 2.1811 - val_loss: 2.5644\n",
      "Epoch 708/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.8103 - val_loss: 2.2410\n",
      "Epoch 709/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.8082 - val_loss: 2.1824\n",
      "Epoch 710/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7300 - val_loss: 2.2477\n",
      "Epoch 711/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6178 - val_loss: 2.2178\n",
      "Epoch 712/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.6705 - val_loss: 2.3080\n",
      "Epoch 713/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.6353 - val_loss: 2.3685\n",
      "Epoch 714/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6627 - val_loss: 2.3009\n",
      "Epoch 715/1000\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.6031 - val_loss: 2.2166\n",
      "Epoch 716/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.9320 - val_loss: 2.3736\n",
      "Epoch 717/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.8557 - val_loss: 2.3270\n",
      "Epoch 718/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6839 - val_loss: 2.5026\n",
      "Epoch 719/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.9531 - val_loss: 2.3745\n",
      "Epoch 720/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.6750 - val_loss: 2.2358\n",
      "Epoch 721/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6866 - val_loss: 2.1311\n",
      "Epoch 722/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6285 - val_loss: 2.2203\n",
      "Epoch 723/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.6925 - val_loss: 2.3955\n",
      "Epoch 724/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6645 - val_loss: 2.5230\n",
      "Epoch 725/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7804 - val_loss: 2.5237\n",
      "Epoch 726/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8040 - val_loss: 2.1703\n",
      "Epoch 727/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7192 - val_loss: 2.1024\n",
      "Epoch 728/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7125 - val_loss: 2.1086\n",
      "Epoch 729/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6561 - val_loss: 2.2749\n",
      "Epoch 730/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7014 - val_loss: 2.2581\n",
      "Epoch 731/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.5540 - val_loss: 2.2597\n",
      "Epoch 732/1000\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.5712 - val_loss: 2.3163\n",
      "Epoch 733/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7373 - val_loss: 2.3277\n",
      "Epoch 734/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7328 - val_loss: 2.3109\n",
      "Epoch 735/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6348 - val_loss: 2.2919\n",
      "Epoch 736/1000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1.6294 - val_loss: 2.2733\n",
      "Epoch 737/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5985 - val_loss: 2.2018\n",
      "Epoch 738/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7250 - val_loss: 2.2370\n",
      "Epoch 739/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.7260 - val_loss: 2.2896\n",
      "Epoch 740/1000\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.7997 - val_loss: 2.2225\n",
      "Epoch 741/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7293 - val_loss: 2.2091\n",
      "Epoch 742/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7836 - val_loss: 2.2677\n",
      "Epoch 743/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.6602 - val_loss: 2.2334\n",
      "Epoch 744/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6857 - val_loss: 2.2172\n",
      "Epoch 745/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.7910 - val_loss: 2.5258\n",
      "Epoch 746/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7782 - val_loss: 2.2660\n",
      "Epoch 747/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.7520 - val_loss: 2.2575\n",
      "Epoch 748/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7849 - val_loss: 2.3368\n",
      "Epoch 749/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5711 - val_loss: 2.2405\n",
      "Epoch 750/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.5406 - val_loss: 2.4156\n",
      "Epoch 751/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.6725 - val_loss: 2.3123\n",
      "Epoch 752/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6754 - val_loss: 2.2025\n",
      "Epoch 753/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5997 - val_loss: 2.3063\n",
      "Epoch 754/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6386 - val_loss: 2.2240\n",
      "Epoch 755/1000\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 1.7161 - val_loss: 2.2439\n",
      "Epoch 756/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6558 - val_loss: 2.2683\n",
      "Epoch 757/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7287 - val_loss: 2.2639\n",
      "Epoch 758/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7343 - val_loss: 2.2864\n",
      "Epoch 759/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.6331 - val_loss: 2.2936\n",
      "Epoch 760/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.7324 - val_loss: 2.3233\n",
      "Epoch 761/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7118 - val_loss: 2.1606\n",
      "Epoch 762/1000\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.6600 - val_loss: 2.2866\n",
      "Epoch 763/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.8160 - val_loss: 2.2064\n",
      "Epoch 764/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6713 - val_loss: 2.2007\n",
      "Epoch 765/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.5190 - val_loss: 2.2878\n",
      "Epoch 766/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6126 - val_loss: 2.3077\n",
      "Epoch 767/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7073 - val_loss: 2.3091\n",
      "Epoch 768/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6293 - val_loss: 2.1626\n",
      "Epoch 769/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.7270 - val_loss: 2.3037\n",
      "Epoch 770/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.6264 - val_loss: 2.3256\n",
      "Epoch 771/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7577 - val_loss: 2.4512\n",
      "Epoch 772/1000\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 2.0417 - val_loss: 2.5207\n",
      "Epoch 773/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6699 - val_loss: 2.3315\n",
      "Epoch 774/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6704 - val_loss: 2.2619\n",
      "Epoch 775/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.6941 - val_loss: 2.3482\n",
      "Epoch 776/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.6340 - val_loss: 2.2299\n",
      "Epoch 777/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5746 - val_loss: 2.1804\n",
      "Epoch 778/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5902 - val_loss: 2.2165\n",
      "Epoch 779/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6736 - val_loss: 2.2704\n",
      "Epoch 780/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.6576 - val_loss: 2.2684\n",
      "Epoch 781/1000\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.7019 - val_loss: 2.3369\n",
      "Epoch 782/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6634 - val_loss: 2.2657\n",
      "Epoch 783/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6244 - val_loss: 2.2675\n",
      "Epoch 784/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5401 - val_loss: 2.2498\n",
      "Epoch 785/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5964 - val_loss: 2.2598\n",
      "Epoch 786/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6463 - val_loss: 2.1996\n",
      "Epoch 787/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.8069 - val_loss: 2.1478\n",
      "Epoch 788/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.5683 - val_loss: 2.1108\n",
      "Epoch 789/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7673 - val_loss: 2.3272\n",
      "Epoch 790/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7031 - val_loss: 2.2829\n",
      "Epoch 791/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.6326 - val_loss: 2.2514\n",
      "Epoch 792/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6454 - val_loss: 2.3393\n",
      "Epoch 793/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6166 - val_loss: 2.2520\n",
      "Epoch 794/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7044 - val_loss: 2.2675\n",
      "Epoch 795/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.7738 - val_loss: 2.3336\n",
      "Epoch 796/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.7321 - val_loss: 2.2666\n",
      "Epoch 797/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.7217 - val_loss: 2.2553\n",
      "Epoch 798/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6051 - val_loss: 2.2615\n",
      "Epoch 799/1000\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.6649 - val_loss: 2.2914\n",
      "Epoch 800/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6591 - val_loss: 2.2990\n",
      "Epoch 801/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7112 - val_loss: 2.2347\n",
      "Epoch 802/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.5779 - val_loss: 2.2419\n",
      "Epoch 803/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7329 - val_loss: 2.2958\n",
      "Epoch 804/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.6773 - val_loss: 2.1822\n",
      "Epoch 805/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7204 - val_loss: 2.2685\n",
      "Epoch 806/1000\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.7087 - val_loss: 2.3763\n",
      "Epoch 807/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.7745 - val_loss: 2.2867\n",
      "Epoch 808/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7572 - val_loss: 2.3891\n",
      "Epoch 809/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.6512 - val_loss: 2.4033\n",
      "Epoch 810/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6717 - val_loss: 2.0998\n",
      "Epoch 811/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.5749 - val_loss: 2.2014\n",
      "Epoch 812/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.5620 - val_loss: 2.2312\n",
      "Epoch 813/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.5941 - val_loss: 2.2474\n",
      "Epoch 814/1000\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 1.6861 - val_loss: 2.2961\n",
      "Epoch 815/1000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1.5705 - val_loss: 2.3319\n",
      "Epoch 816/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7858 - val_loss: 2.2945\n",
      "Epoch 817/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6497 - val_loss: 2.2525\n",
      "Epoch 818/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6392 - val_loss: 2.2758\n",
      "Epoch 819/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6041 - val_loss: 2.3257\n",
      "Epoch 820/1000\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 1.8771 - val_loss: 2.6295\n",
      "Epoch 821/1000\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 1.7325 - val_loss: 2.3348\n",
      "Epoch 822/1000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1.6682 - val_loss: 2.2970\n",
      "Epoch 823/1000\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1.5856 - val_loss: 2.3126\n",
      "Epoch 824/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7464 - val_loss: 2.5053\n",
      "Epoch 825/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.5872 - val_loss: 2.3695\n",
      "Epoch 826/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6471 - val_loss: 2.2427\n",
      "Epoch 827/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7289 - val_loss: 2.2414\n",
      "Epoch 828/1000\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 1.6209 - val_loss: 2.2938\n",
      "Epoch 829/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.7654 - val_loss: 2.3903\n",
      "Epoch 830/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6574 - val_loss: 2.3598\n",
      "Epoch 831/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6682 - val_loss: 2.3119\n",
      "Epoch 832/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.6824 - val_loss: 2.2461\n",
      "Epoch 833/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.5961 - val_loss: 2.2386\n",
      "Epoch 834/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6918 - val_loss: 2.3802\n",
      "Epoch 835/1000\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 1.7307 - val_loss: 2.2537\n",
      "Epoch 836/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7859 - val_loss: 2.2070\n",
      "Epoch 837/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6474 - val_loss: 2.3078\n",
      "Epoch 838/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.6814 - val_loss: 2.3210\n",
      "Epoch 839/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6160 - val_loss: 2.3149\n",
      "Epoch 840/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5946 - val_loss: 2.2511\n",
      "Epoch 841/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6337 - val_loss: 2.3064\n",
      "Epoch 842/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5782 - val_loss: 2.2244\n",
      "Epoch 843/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.6765 - val_loss: 2.2368\n",
      "Epoch 844/1000\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 1.5817 - val_loss: 2.2819\n",
      "Epoch 845/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.8282 - val_loss: 2.5183\n",
      "Epoch 846/1000\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.6440 - val_loss: 2.3600\n",
      "Epoch 847/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.6717 - val_loss: 2.2810\n",
      "Epoch 848/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5732 - val_loss: 2.2434\n",
      "Epoch 849/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.5683 - val_loss: 2.2701\n",
      "Epoch 850/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.7126 - val_loss: 2.2534\n",
      "Epoch 851/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6006 - val_loss: 2.3316\n",
      "Epoch 852/1000\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 1.8007 - val_loss: 2.5220\n",
      "Epoch 853/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7142 - val_loss: 2.2345\n",
      "Epoch 854/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6045 - val_loss: 2.2338\n",
      "Epoch 855/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.5737 - val_loss: 2.2600\n",
      "Epoch 856/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6472 - val_loss: 2.3445\n",
      "Epoch 857/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.5478 - val_loss: 2.2930\n",
      "Epoch 858/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5951 - val_loss: 2.2936\n",
      "Epoch 859/1000\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.6299 - val_loss: 2.2092\n",
      "Epoch 860/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6757 - val_loss: 2.2768\n",
      "Epoch 861/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5490 - val_loss: 2.2518\n",
      "Epoch 862/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6917 - val_loss: 2.2653\n",
      "Epoch 863/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7319 - val_loss: 2.3531\n",
      "Epoch 864/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7066 - val_loss: 2.5681\n",
      "Epoch 865/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7379 - val_loss: 2.2589\n",
      "Epoch 866/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6871 - val_loss: 2.3003\n",
      "Epoch 867/1000\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 1.5864 - val_loss: 2.3733\n",
      "Epoch 868/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6001 - val_loss: 2.1823\n",
      "Epoch 869/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6944 - val_loss: 2.1495\n",
      "Epoch 870/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.6285 - val_loss: 2.2007\n",
      "Epoch 871/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6945 - val_loss: 2.2790\n",
      "Epoch 872/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6838 - val_loss: 2.3148\n",
      "Epoch 873/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.6490 - val_loss: 2.2316\n",
      "Epoch 874/1000\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 1.5585 - val_loss: 2.2445\n",
      "Epoch 875/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.6411 - val_loss: 2.2057\n",
      "Epoch 876/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6899 - val_loss: 2.2213\n",
      "Epoch 877/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5830 - val_loss: 2.3604\n",
      "Epoch 878/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8501 - val_loss: 2.2834\n",
      "Epoch 879/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8044 - val_loss: 2.0715\n",
      "Epoch 880/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6654 - val_loss: 2.1857\n",
      "Epoch 881/1000\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.7077 - val_loss: 2.2924\n",
      "Epoch 882/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.6418 - val_loss: 2.1729\n",
      "Epoch 883/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6146 - val_loss: 2.2371\n",
      "Epoch 884/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7134 - val_loss: 2.2860\n",
      "Epoch 885/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.7474 - val_loss: 2.4255\n",
      "Epoch 886/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6398 - val_loss: 2.3310\n",
      "Epoch 887/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.6866 - val_loss: 2.1910\n",
      "Epoch 888/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.5796 - val_loss: 2.3348\n",
      "Epoch 889/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7192 - val_loss: 2.2107\n",
      "Epoch 890/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6162 - val_loss: 2.1030\n",
      "Epoch 891/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6593 - val_loss: 2.2904\n",
      "Epoch 892/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5717 - val_loss: 2.2826\n",
      "Epoch 893/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7149 - val_loss: 2.2970\n",
      "Epoch 894/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5566 - val_loss: 2.3816\n",
      "Epoch 895/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.5553 - val_loss: 2.1740\n",
      "Epoch 896/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6289 - val_loss: 2.1907\n",
      "Epoch 897/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.7352 - val_loss: 2.2944\n",
      "Epoch 898/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6028 - val_loss: 2.2902\n",
      "Epoch 899/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.4845 - val_loss: 2.2473\n",
      "Epoch 900/1000\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.6099 - val_loss: 2.2497\n",
      "Epoch 901/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6669 - val_loss: 2.3154\n",
      "Epoch 902/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6900 - val_loss: 2.2548\n",
      "Epoch 903/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7826 - val_loss: 2.1690\n",
      "Epoch 904/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.6269 - val_loss: 2.1869\n",
      "Epoch 905/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.5451 - val_loss: 2.2145\n",
      "Epoch 906/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6094 - val_loss: 2.2426\n",
      "Epoch 907/1000\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 1.5355 - val_loss: 2.2615\n",
      "Epoch 908/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6036 - val_loss: 2.3330\n",
      "Epoch 909/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6365 - val_loss: 2.4218\n",
      "Epoch 910/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.6415 - val_loss: 2.3309\n",
      "Epoch 911/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.5406 - val_loss: 2.2752\n",
      "Epoch 912/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5720 - val_loss: 2.2011\n",
      "Epoch 913/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5760 - val_loss: 2.2826\n",
      "Epoch 914/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6428 - val_loss: 2.2104\n",
      "Epoch 915/1000\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 1.5937 - val_loss: 2.2469\n",
      "Epoch 916/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.6215 - val_loss: 2.3242\n",
      "Epoch 917/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.6847 - val_loss: 2.5680\n",
      "Epoch 918/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6566 - val_loss: 2.1329\n",
      "Epoch 919/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.7405 - val_loss: 2.0994\n",
      "Epoch 920/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6058 - val_loss: 2.1463\n",
      "Epoch 921/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.4728 - val_loss: 2.1016\n",
      "Epoch 922/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6950 - val_loss: 2.1746\n",
      "Epoch 923/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.5942 - val_loss: 2.2549\n",
      "Epoch 924/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.5693 - val_loss: 2.2965\n",
      "Epoch 925/1000\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.6077 - val_loss: 2.3406\n",
      "Epoch 926/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6760 - val_loss: 2.2531\n",
      "Epoch 927/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.7126 - val_loss: 2.3814\n",
      "Epoch 928/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.4561 - val_loss: 2.3438\n",
      "Epoch 929/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5603 - val_loss: 2.2469\n",
      "Epoch 930/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.6897 - val_loss: 2.2513\n",
      "Epoch 931/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6329 - val_loss: 2.3638\n",
      "Epoch 932/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6858 - val_loss: 2.3115\n",
      "Epoch 933/1000\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.7066 - val_loss: 2.2393\n",
      "Epoch 934/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5666 - val_loss: 2.2591\n",
      "Epoch 935/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.6504 - val_loss: 2.3171\n",
      "Epoch 936/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6322 - val_loss: 2.3039\n",
      "Epoch 937/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.6863 - val_loss: 2.2525\n",
      "Epoch 938/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6763 - val_loss: 2.2063\n",
      "Epoch 939/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5205 - val_loss: 2.2369\n",
      "Epoch 940/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6160 - val_loss: 2.2961\n",
      "Epoch 941/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6072 - val_loss: 2.4350\n",
      "Epoch 942/1000\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 1.7299 - val_loss: 2.3111\n",
      "Epoch 943/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.5791 - val_loss: 2.3405\n",
      "Epoch 944/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7035 - val_loss: 2.2996\n",
      "Epoch 945/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6521 - val_loss: 2.3200\n",
      "Epoch 946/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6632 - val_loss: 2.3261\n",
      "Epoch 947/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7241 - val_loss: 2.1653\n",
      "Epoch 948/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6792 - val_loss: 2.2402\n",
      "Epoch 949/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.5373 - val_loss: 2.2175\n",
      "Epoch 950/1000\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 1.6809 - val_loss: 2.3641\n",
      "Epoch 951/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6049 - val_loss: 2.2558\n",
      "Epoch 952/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6167 - val_loss: 2.2664\n",
      "Epoch 953/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5216 - val_loss: 2.2365\n",
      "Epoch 954/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5629 - val_loss: 2.2601\n",
      "Epoch 955/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6939 - val_loss: 2.2476\n",
      "Epoch 956/1000\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.5684 - val_loss: 2.1860\n",
      "Epoch 957/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6793 - val_loss: 2.1364\n",
      "Epoch 958/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.6000 - val_loss: 2.2365\n",
      "Epoch 959/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.6179 - val_loss: 2.2846\n",
      "Epoch 960/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6173 - val_loss: 2.2974\n",
      "Epoch 961/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6763 - val_loss: 2.2410\n",
      "Epoch 962/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5302 - val_loss: 2.2716\n",
      "Epoch 963/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5541 - val_loss: 2.2432\n",
      "Epoch 964/1000\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 1.5206 - val_loss: 2.2468\n",
      "Epoch 965/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.5680 - val_loss: 2.1398\n",
      "Epoch 966/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5965 - val_loss: 2.3143\n",
      "Epoch 967/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7131 - val_loss: 2.1173\n",
      "Epoch 968/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6333 - val_loss: 2.2456\n",
      "Epoch 969/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.8211 - val_loss: 2.5647\n",
      "Epoch 970/1000\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 1.6802 - val_loss: 2.2366\n",
      "Epoch 971/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7261 - val_loss: 2.2351\n",
      "Epoch 972/1000\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.5435 - val_loss: 2.3430\n",
      "Epoch 973/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.4984 - val_loss: 2.2797\n",
      "Epoch 974/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.5337 - val_loss: 2.3279\n",
      "Epoch 975/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6036 - val_loss: 2.4010\n",
      "Epoch 976/1000\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1.5082 - val_loss: 2.1783\n",
      "Epoch 977/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.5782 - val_loss: 2.0940\n",
      "Epoch 978/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6100 - val_loss: 2.1431\n",
      "Epoch 979/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.4758 - val_loss: 2.2161\n",
      "Epoch 980/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7819 - val_loss: 2.4305\n",
      "Epoch 981/1000\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.6948 - val_loss: 2.2351\n",
      "Epoch 982/1000\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 1.6098 - val_loss: 2.2084\n",
      "Epoch 983/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.5452 - val_loss: 2.2461\n",
      "Epoch 984/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6159 - val_loss: 2.1962\n",
      "Epoch 985/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5723 - val_loss: 2.2126\n",
      "Epoch 986/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6413 - val_loss: 2.2691\n",
      "Epoch 987/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5015 - val_loss: 2.2981\n",
      "Epoch 988/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.5629 - val_loss: 2.2823\n",
      "Epoch 989/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7782 - val_loss: 2.3060\n",
      "Epoch 990/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6262 - val_loss: 2.2609\n",
      "Epoch 991/1000\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 1.6646 - val_loss: 2.1892\n",
      "Epoch 992/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.6188 - val_loss: 2.3048\n",
      "Epoch 993/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6438 - val_loss: 2.1930\n",
      "Epoch 994/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5986 - val_loss: 2.1308\n",
      "Epoch 995/1000\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1.6294 - val_loss: 2.1224\n",
      "Epoch 996/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5313 - val_loss: 2.1855\n",
      "Epoch 997/1000\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1.6583 - val_loss: 2.1402\n",
      "Epoch 998/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6250 - val_loss: 2.2494\n",
      "Epoch 999/1000\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.5752 - val_loss: 2.1518\n",
      "Epoch 1000/1000\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5737 - val_loss: 2.1633\n"
     ]
    }
   ],
   "source": [
    "## we train the data and test the validation\n",
    "\n",
    "model_history = model.fit(x = x_train, y = y_train, validation_data = (x_val, y_val), batch_size= 32, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step - loss: 2.4257\n"
     ]
    }
   ],
   "source": [
    "## model evalution\n",
    "test_score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'val_loss'])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(model_history.history)\n",
    "df.plot()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 0s/step\n",
      "[18.181812]\n",
      "18.8\n"
     ]
    }
   ],
   "source": [
    "#model save\n",
    "model.save(\"Boston_house_model.h5\")\n",
    "\n",
    "#load data\n",
    "model = tf.keras.models.load_model(\"Boston_house_model.h5\")\n",
    "\n",
    "#predict\n",
    "\n",
    "ypred = model.predict(x_test)\n",
    "print(ypred[1])\n",
    "print(y_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8201822030675652"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## metric is done\n",
    "## we use r2 square metrics\n",
    "## we want an r2 square of 1 because of the variance. if it predicts high, it should be high and vice versa\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "test = r2_score(y_test, ypred )\n",
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
